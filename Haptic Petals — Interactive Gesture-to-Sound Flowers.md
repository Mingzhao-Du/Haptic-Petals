# Haptic Petals

<img width="1994" height="1114" alt="Haptic Petals_cover" src="https://github.com/user-attachments/assets/93641d84-c3c1-46c1-b8cf-56adb00e5c05" />

---

## Project Description
Haptic Petals is an interactive installation that explores the relationship between humans, technology, and the environment. It imagines a near future where natural forms—such as flowers—are no longer purely organic, but digitally reconstructed and emotionally reactive. The project poses a central question: how do we coexist with hybrid ecologies shaped by nature and code?

Rather than representing flowers as static symbols of nature, we treated them as living, breathing digital entities. The flower model in our project responds not only to external stimuli but also to its subtle rhythms, suggesting that digital objects can possess a kind of ambient vitality.

What we learned through this project is that emotional expression and environmental awareness can be encoded into interaction design. Technologies are not only tools for control, but also mediums for rethinking care, rhythm, and ecological coexistence. Haptic Petals invites users to reflect on their gestures—not just as inputs, but as ethical encounters with new forms of digital life.

---

## Technical Description
This project was developed using TouchDesigner as the core visual programming platform, combined with Leap Motion for gesture recognition. The system includes two main components: audio-driven environmental interaction and gesture-based visual control. A 3D flower model was imported and processed into a point cloud representation. When no hand is detected, the model autonomously rotates based on noise patterns synced to the rhythm of ambient music. Once a gesture is recognized, control shifts from music to the user’s hand, allowing real-time manipulation of the model’s structure and behaviour, emphasizing a dynamic relationship between sensory input and visual response.

---

## Individual Contribution
I was responsible for building and integrating the 3D flower model. This included creating the structure using modelling tools, optimizing the topology for real-time rendering in TouchDesigner, and importing it into the system with adjusted materials, coordinates, and scale. I also led final debugging and user testing, focusing on Leap Motion gesture accuracy, audio-visual synchronization, and overall system stability. My work ensured a smooth and responsive interaction experience.

---

## Project Images

<img width="3201" height="1801" alt="Mood Board" src="https://github.com/user-attachments/assets/91d106e4-ac66-4029-addd-b753e6fc5145" />

![8](https://github.com/user-attachments/assets/abe95c1d-1331-4ae8-96ca-ff2d3e9554f4)

![2](https://github.com/user-attachments/assets/2496b72f-74d6-4565-b565-a2355b5c2d6b)

![3](https://github.com/user-attachments/assets/150aa686-00c7-4d7f-a928-a6b45c0dc0e1)

![7](https://github.com/user-attachments/assets/38b65105-8258-4de4-b359-759e6f5af47d)

---

## Project Demo
Link to a demo video: https://mega.nz/file/DiowAbLa#I00CQr59C9aJkCXB6Qli9LqqIgc15w6tj6GhijIIK_8

The demo video showcases Haptic Petals, an interactive installation that explores the intersection of human emotion, digital ecology, and gesture-based interaction. Using 3D scans of real flowers processed into point cloud visuals, the system responds to both ambient sound and hand gestures tracked by Leap Motion.

The video highlights the flower model’s dual behaviour: in passive mode, it rotates organically in sync with background music, suggesting a digital “breathing” rhythm; in interactive mode, hand gestures override this flow. An open hand triggers expansion and gentle blooming, while a closed fist causes fragmentation and dispersal—visual metaphors for emotional states and ecological tension.

The visuals demonstrate how the system maintains a dynamic feedback loop between the user and the digital environment, reinforcing the project’s core theme: how we perceive, disrupt, and coexist with emerging hybrid ecologies shaped by both nature and technology.

---

## Github Link to all project files and assets 

https://github.com/Mingzhao-Du/Haptic-Petals/tree/main/Project%20Files

---

## User Testing & Proposed Revisions
To assess the interaction quality and user experience of our project, we conducted simulated testing with five participants from varied creative and technical backgrounds. Feedback was evaluated using standard usability principles relevant to interactive installations.

Participants generally found the gesture-based interaction intuitive and visually compelling. The symbolic mapping—open hand for flow and balance, closed fist for fragmentation and control—was well received. However, some noted unclear feedback when the system shifted from audio-driven to gesture-based control, while others suggested expanding gesture complexity to improve user agency and immersion.

Based on this feedback, we propose the following revisions: (1) Introducing more explicit visual cues (e.g., colour pulses or transparency shifts) or subtle audio signals to indicate control transitions; (2) Optimizing the recognition sensitivity and active range of the Leap Motion sensor to guide users toward ideal interaction distances; (3) Expanding the gesture vocabulary by incorporating variables such as hand rotation, finger positioning, and bilateral coordination to control model deformation, colour, or rhythm; (4) Finally, implementing “micro-interactions” during idle states—such as triggering petal movement through minimal fingertip gestures—to maintain a sense of ambient vitality.

These proposed enhancements would significantly enrich the system’s complexity and expressive capacity in terms of interaction logic, emotional resonance, and fine-grained control. Not only would they increase users’ sense of immersion and agency, but they would also enable the system to respond more sensitively to subtle perceptual inputs, fostering a more layered and effectively rich human-machine relationship. Ultimately, these refinements would help realize our core vision of a “digital life form,” transforming the installation from a reactive tool into a sensorial and ecologically attuned presence.


https://github.com/user-attachments/assets/d4882bbf-ad3f-4700-b25c-f8b4d4d523d8


![1b0303328f55ac1e09a389878264d9e](https://github.com/user-attachments/assets/cde53da8-36f4-43c6-9757-78c38401661f)

![1f1bca55f2c56992f19837fc9f45652](https://github.com/user-attachments/assets/db317e04-9b3d-425c-bb87-5cf22cdd8cd9)

![a56d915f33b6164f3edabbf38a7ac89](https://github.com/user-attachments/assets/c8545392-062b-43f3-8012-86b7edcf4e5c)

![e8999a52a299cd047bae8ac8c95fa6d](https://github.com/user-attachments/assets/cf7669eb-52de-42cb-80e9-cbfac1936264)

![2113972d4ee69d39bc78f5335c0ea17](https://github.com/user-attachments/assets/b875d8a5-ed83-4df6-883a-22e206de97dc)

---

## Reflection
By reviewing the recording of our presentation, we could critically reflect on the strengths and areas for improvement in our delivery. We were pleased to receive positive feedback from peers and tutors regarding the visual aesthetics, model design, point cloud effects, and the poetic quality of our conceptual framing. In particular, the symbolic interplay between gesture-based interaction and the tension between digital and natural forms was widely recognized and appreciated.

At the same time, several constructive comments helped us identify points for refinement. Some viewers found our explanation of the project’s motivation and conceptual background unclear. This was largely due to our lack of control over the 20-second time limit per slide—certain key ideas, especially those in the opening section, were cut off mid-sentence by automatic transitions. In addition, our technical explanation was occasionally rushed, especially in the transition from visual aesthetics to system architecture, resulting in a slightly uneven pacing.

In future presentations, we plan to further streamline our script, eliminate non-essential content, and prioritize key messages early on. We also recognize that thorough rehearsal is essential for ensuring clarity and composure. Most importantly, this experience reminded us that presenting a creative-technological project is not merely about showcasing function, but about communicating the conceptual intent, design rationale, and emotional resonance behind it.

<img width="1144" height="799" alt="Feedback" src="https://github.com/user-attachments/assets/737c84c4-04c1-45b2-a8d6-e1f8aab20d2e" />

---
