### Labs

This week, my team and I devoted ourselves fully to the final stage of the project. After multiple rounds of testing and fine-tuning, we successfully realised the intended integration of audio and gesture interaction. The system now operates with stability and delivers the interactive experience we initially envisioned. Meanwhile, the visual presentation has also largely achieved the goals we set at the beginning of the project.

<img width="862" height="860" alt="eca19925b3dba3d0587a3f8c37576d0b" src="https://github.com/user-attachments/assets/57ced787-7bab-4499-8111-d76ea954b378" />

<img width="825" height="830" alt="c685060d69551babc7ef6ffbd84a5164" src="https://github.com/user-attachments/assets/2ef0d465-2454-4eff-b824-85ebeb71297f" />

In preparation for next week's final presentation, we also created a set of demonstration slides. A black background was chosen to enhance visual contrast, and the slides clearly outline the project's core concepts and development trajectory, providing a structured overview from initial ideation to final implementation.

<img width="1918" height="826" alt="ee7242c34235417a4e5e8257d74ebb86" src="https://github.com/user-attachments/assets/e8055e06-b295-4e08-bbff-f204109d1cb8" />

---

### Peer Support

This week, my teammate and I conducted a final review of the system’s overall performance, focusing on the stability of visual outputs and the responsiveness of interactions. During the debugging process, whenever one of us identified minor issues, such as gesture recognition delays or unsmooth particle animations, we communicated promptly, diagnosed the cause together, and adjusted parameters accordingly. We also divided tasks efficiently: I was mainly responsible for tuning the synchronisation between audio and gesture input, while my teammate focused on refining the visual layers. This parallel workflow significantly improved our efficiency when integrating the components for testing.

While preparing the final presentation slides, we collaborated closely on the structure and phrasing of each page, deciding where additional visuals were needed and which technical terms required clearer explanations. This mutual support and real-time feedback greatly streamlined our workflow and strengthened our confidence in the final delivery of the project.

---

### Project Development

As outlined in the “Labs” section, we have now completed the core components of the project, including the final calibration of both the visual system and interaction mechanics.

On the visual side, the digital flower model continuously cycles through a dynamic process of “fragmentation and reconstruction.” A dark background has been applied to highlight the central visual elements. The composition emphasises spatial focus, complemented by shifting texture layers and animated particles that together create a rhythmic visual flow. When no hand gestures are detected, the model responds to the audio rhythm by transitioning states and generating subtle particle vibrations.

In terms of interaction, once Leap Motion detects the presence of a hand, the user can perform open–close gestures above the flower, triggering prominent visual feedback such as deformation, rotation, and expansion of the model. Through multiple rounds of testing, we have thoroughly validated the reliability of gesture recognition, the responsiveness of interaction, and the clarity of the resulting visual feedback, ultimately completing the optimisation of the interactive component.
